\chapter{Theoretical Foundations}
Throughout this thesis we will develop a complicated algorithm. We will relay on existing technology and knowledge throughout the third and the fourth chapter. Thus in this chapter we present a minimal mindset that is helpful to understand the presented algorithm and reproduce our argumentation. The first thing we need is a little background knowledge on the computability of mathematical problems and the algorithms that are applied to the considered problems. The second technology we need prior knowledge about is the \textbf{U}nified \textbf{M}odelling \textbf{L}anguage (UML) and the \textbf{O}bject \textbf{C}onstraint \textbf{L}anguage, since those are the input languages for the presented algorithm. \textbf{A} \textbf{M}athematical \textbf{P}rogramming \textbf{L}anguage (AMPL) is used throughout the presented algorithm thus we will explain the basic concepts of AMPL in this chapter. Further it is also necessary to shortly elaborate on the taxonomy in the field of Model--Based Testing to avoid confusions. Finally, we will present in the section \nameref{sec:RelatedWork} what others did in order to solve similar problems as the one we are going to solve.
\label{chap:preliminaries}
\section{Mathematical Foundations}
\label{sec:Maths}
\begin{figure}
\label{fig:problemLatice}
\includegraphics[width=\textwidth]{./pics/ProblemLatice.pdf}
\caption{Generalisation and specialization dependencies between different problems}
\end{figure}
%When modelling we always need ways to express facts in mathematical terms. E.g from physic we know equations that express the relations between different physical values. 
We are often modelling in order to derive an answer to some particular question. If we are lucky there exists an algorithm and even a software implementation that can compute the answer to our question. A major task in this thesis is to transform an activity diagram to a mathematical program, that is, a constraint satisfaction problem, and to apply a constraint solver. Currently existing solvers are always specialized on a few problems. When selecting a solver one needs to understand of which problem this model is an instance. Depending on the input model the resulting mathematical program will be an instance of one of the problems presented in this section.\\
For some problems like the linear program (\ref{sec:MathLinearProgram}) there exist polynomial time algorithms. An algorithm with polynomial worst case runtime is considered a \emph{tractable} algorithm. For other problems there can be instances that are NP-complete for example the boolean satisfiability (SAT) presented in section \ref{sec:MathBooleanSat}. Any algorithm solving an NP--complete problem will be \emph{intractable}. We consider an algorithm tractable when its worst case runtime is polynomial and intractable when its worst case runtime is exponential.\\
Not every problem presented here will be \emph{decidable}. When a problem is \emph{undecidable} that means there can never be an algorithm solving all instances of this problem. Still there exist heuristic algorithms that try to handle undecidable problems. They may find a solution if they are lucky, or just terminate without finding a solution although one exists, or they might run forever, or even just return a wrong answer. Those heuristics may be tractable or intractable.\\
One needs to understand those two properties, tractability and decidability, in order to know what one can expect from a solver when trying to solve an instance of a problem. If the used algorithm is tractable, we know that we can expect an answer even for large problems after a moderate amount of time. For intractable algorithms the runtime might grow exponentially and thus make it practically infeasible to compute an answer to the problem.\\
When the problem is decidable we can assume that the used solver is exact and will tell that the problem has no solution only if there really is no solution, if it returns a solution we assume it is correct. For instances of undecidable problems a heuristic telling that there is no solution just means, that this particular search was not lucky, and potentially returned answers might not be correct solutions of the given problem. If a heuristic was not lucky and did not find a potential solution one could start again with different parameters for the search algorithm, for example, another starting point, or could use another solver. Typically we are asking for an optimal solution and a heuristic will either find the true optimum, or return a good and practically useful but sub--optimal and thus incorrect answer, or it reports that no possible answer could be found. In practice one will run a mathematical search until a certain time limit is up.\\
In the following we will introduce those constraint satisfaction problems that we think are relevant to generate test data from activity diagrams in practice. We will shortly mention their implications for solvability. In Figure \ref{fig:problemLatice} we give an overview of the problems and visualise which problems are generalisations or specializations of each other. An arrow from A to B means that B is a generalisation of A. In green are those problems that are decidable and have at least one tractable algorithm. Those are the easy--to--solve--problems in practice. All the other problems listed are challenging.
\subsection{Constraint Programming}
\begin{figure}
\label{fig:CSPExample}
\includegraphics[width=0.5\textwidth]{./pics/SetIntersection.pdf}
\caption{Two--dimensional search space and three different subsets forming a constraint satisfaction problem}
\end{figure}
In a \emph{constraint satisfaction problem} (CSP) the task is to assign values $v(x_i)$ to a set of variables $X = (x_1, \dots , x_n)$ from a search space $S=D_1\times \dots \times D_n$ such that all relations $c_1,\dots,c_k$ between the variables hold. We call those relations $c_1,\dots,c_k$ \emph{constraints}. $D_i$ is called the domain of $x_i$, $n$ is the number of variables, and $k$ the number of constraints. We can formalise a constraint satisfaction problem as shown in equations (\ref{CSP})--(\ref{CSPEnd}) \cite{Eiben97constraintsatisfaction}\cite{wiki:CSP}.
\begin{eqnarray} 
\label{CSP}
c_i \subseteq S \qquad\forall i \in \left[ 1 \dots k \right]\\
\text{find:} \quad v(x_i) \in D_i \qquad\forall i \in \left[ 1 \dots n \right]| \\
\label{CSPEnd}
\text{subject to:} \quad (v(x_1),\dots , v(x_n)) \in c_j\qquad\forall j \in \left[1 \dots k\right]
\end{eqnarray} 
Any point in $S$ fulfilling all constraints is called a \emph{feasible solution}. The set of all feasible solutions is called the \emph{feasible set}. The feasible set is the intersection of all constraints. If the feasible set is the empty set we call the problem infeasible. Solving a constraint satisfaction problem means finding one feasible solution.\\
Practically, constraints are often specified as boolean terms over a subset of $X$. For example $x_1=x_2$ specifies a constraint. A constraint can also be specified by only one variable as in $0\leq x_1 \leq 1$. It is possible to extend any relation between $x_1$ and $x_2$ to a n-ary relation between $x_1,\dots,x_n$. In the extended relation all possible values are permitted for the variables not contained in the term.\\
In general, there are no restrictions on the domains of the variables and the search space. They could be continuous, discrete, finite and infinite. Well known domains are integer, real, boolean but city names or all triangles similar to an equilateral triangle could also form a domain. Similarly, the constraints can have arbitrary properties. Even a fractal set would be acceptable as constraint. In literature about constraint programming often finite discrete search spaces are assumed \cite{Citation Needed}. In fact, on a computer, a real number is stored in IEEE 754 floating point format, which is a finite discretization of the real numbers. \\
In Figure \ref{fig:CSPExample} we can see a two--dimensional continuous search space and three sets. One that could be assembled by a union of intersections of half--spaces, another that has an arbitrary shape, and the last set that consists of discrete points marked by the crosses. Any of the points within the intersection of those three sets is a solution to the corresponding CSP.\\
The CSP in its general form is undecidable but with restrictions on the kind of constraints and domains it becomes decidable. For example a CSP with all variables in $\mathbb{B}$ is decidable. We therefore reduce our expectations and consider those specializations, for which algorithms exist. Among the decidable specializations of a CSP those with a tractable algorithm are especially easy--to--solve. Whenever it is possible to state a certain problem as an instance of such an easy--to--solve problem one can be sure that there is a suitable solver solving the problem correct in a moderate amount of time.\\
In practice it is not always easy or impossible to state a question as an instance of a decidable problem having a tractable algorithm. So we will also consider decidable problems with intractable algorithms as well as undecidable problems with tractable and intractable heuristics. A solver is still useful in practice if the worst case runtime is exponential but only for some specially crafted problem instances the worst case happens.%The simplex algorithm is a good example for such an algorithm. Its worst case runtime is exponential but for problems occurring in practice its runtime grows linear with the number of constraints.
For practical problems it is often the case, that an intractable algorithm has a non--exponential average runtime. 
For undecidable problems there exist heuristics that give useful answers to a given problem instance. The answer of a heuristic may not be perfectly correct for example it can return a sub-optimal point for an optimisation. In most cases the answer of a heuristic is good enough to be useful in practice. We are especially interested in specializations of the CSP that impose as little constraints on the domains and constraint formulations as possible and are just specialized enough that we can find a solver that reports useful answers for practical instances after a moderate amount of time. Those are the user--friendly specializations fo the CSP, since the user stating the problem does not need to care for to many restrictions on the way he formulates the problem.
%There is no way to handle all possible ways to describe the constraints by one single algorithm. Additionally this general form includes also a lot of problems that are known to be undecidable or just infeasible to compute. Consequently we need to look at several specializations. //BULLSHITT!!!!
%A constraint $c_j$ is a pair $<t_j,R_j>$ of a set of variables $t_j$ and a relation $R_j$. $t_j$ is a subset of X and R is defined over those variables.

\subsection{Mathematical Programming}
A \emph{Mathematical Program} or \emph{Optimisation Problem} (OP) is a constraint satisfaction problem with a real-valued \emph{objective function} $f:S\mapsto \mathbb{R}$ where constraints are specified in terms of functions $g_1,\dots,g_k:S\mapsto\mathbb{R}$. We call those functions \emph{constraint functions}. The search space is $\mathbb{R}^n$. The task is to find a feasible point that minimises the objective function $f$.
\begin{eqnarray}
\text{minimise:} \quad f(X)\\
\text{subject to:} \quad g_i(X)\leq 0 \qquad \forall i\in\left[1,\dots ,k\right] \label{eqn:MOPs.t.}
\end{eqnarray}
We distinguish two kinds of optima, the local optimum and the global optimum. Global optima are in general much more difficult to find than local optima.
\begin{definition}[local optimum]
A local optimum is a feasible solution that minimises the objective function within a neighbouring set of feasible solutions.
\end{definition}
\begin{definition}[global optimum]
A global optimum is a feasible solution that gives the minimal value for the objective function among all feasible solutions.
\end{definition}
In practice equations are also used as constraints. In Equation (\ref{eqn:MOPs.t.}), $\leq$ is permitted as well as an arbitrary constant on the right--hand side. \\
In this thesis only linear objective functions are considered. For linear objective functions that are not constant any optimum can be found on the boundaries of the feasible set. That is why the word \emph{boundary value} will be used as an equivalent for local optimum. Using a constant objective function relaxes the problem, since with a constant objective function every feasible point is a global optimum.\\
The OP is undecidable, but there are very successful heuristics available. One way to tackle an OP is to add quadratic penalty terms to the objective function, which are growing when a constraint is violated. Then one selects an arbitrary starting point and applies a descend method such as Newton's method to find a local minimum of the augmented objective function. One can try this local search with a descend method multiple times from different starting points and then select among the points found the one that gives the lowest value for the objective function. With a high likelihood, this algorithm will find a feasible point, and the global optimum could have been among the computed local optima.
\subsection{Convex Optimisation}
The \emph{convex optimisation problem} (COP) is one specialization of the optimisation problem for which tractable algorithms exist \cite{Boyd04ConOpt}.
\begin{definition}[convex set]
A set $C$ in a vector space $S$ is said to be convex if, for all points $x$ and $y$ in $C$ and all $t\in\left[0,1\right]$, the point $(1-t)x+ty$ is in $C$.
\end{definition}
\begin{definition}[convex function]
A function f is convex iff for any two values $x$ and $y$ the inequality $ f(\theta x + (1-\theta) y)\leq \theta f(x)+(1-\theta) f(y)$ with $\theta\in \left[0,1\right] $ holds.
\end{definition}
A convex optimisation problem is a mathematical program with a convex objective function and convex constraint functions. The intersection of convex sets is a convex set itself and the set $\left\lbrace x\in\mathbb{R}^n|g_i(x)\leq 0\right\rbrace$ is a convex set. Consequently the feasible set is also convex. For convex problems every local optimum is a global optimum.\\
The convex optimisation problem is decidable and additionally there are tractable interior point methods solving instances of that problem. Interior point methods first need a feasible point as starting point. The objective function is augmented by logarithmic barrier functions for each constraint with a form factor to steer the steepness of these barriers. Now a descend method is applied to find the lowest point. Then repeatedly the barriers are made steeper and the last point found is used as a new starting point. The repetition ends when a stop criterion is fulfilled.
\subsection{Linear Programming}
\label{sec:MathLinearProgram}
Within the class of convex optimisation problems there exist many special cases. One specialization of convex programming is \emph{linear programming} (LP).
In a linear program every constraint can be represented as linear inequality and the objective function is an affine function. 
The canonical form of a linear program consists of a matrix $\mathbf{A}$ and two vectors ${c}$ and ${b}$ as shown in the equations (\ref{linDef})-(\ref{linDefEnd}). The relation $\leq$ is evaluated componentwise.
\begin{eqnarray}
\label{linDef}
\text{minimise:}\quad {c}^TX \\
\label{linDefEnd}
\text{subject to:}\quad AX\leq{b}
\end{eqnarray}
By removing the objective function or setting ${c} = {0} $ the problem is relaxed to a linear constraint satisfaction problem. Formulations containing also equations in the constraints on some components of $X$ can be transformed to an equivalent problem in the canonical form. Also, maximisation of the objective function might be required instead of a minimisation. Further the relation $\geq$ might replace the $\leq$ for some components of the constraint. In practice we will use all of these formulations.\\
An example of a linear program is given in equations (\ref{linExample})-(\ref{linExampleEnd}).
\begin{eqnarray}
\label{linExample}
\begin{pmatrix}
1 & -2 & 3 \\
4 & 5 & 6 
\end{pmatrix}\times\begin{pmatrix}
x_1 \\ x_2 \\ x_3
\end{pmatrix} = \begin{pmatrix}
1 \\ 4
\end{pmatrix}\\
\begin{pmatrix}
0&-1&0
\end{pmatrix}\times\begin{pmatrix}
x_1 \\ x_2 \\ x_3
\label{linExampleEnd}
\end{pmatrix}\leq \vec{0}
\end{eqnarray}
For constraint satisfaction and constrained optimisation with linear constraints and objective function usually an implementation of the simplex algorithm \cite{dantzig63Simplex} can to solve it very efficiently. Although its worst case runtime is exponential the average runtime grows linear with the number of constraints. For a geometric interpretation of the simplex algorithm we interpret the constraints as a set of hyper--planes in an $n$--dimensional space. The feasible region is a polyeder whose faces are within the hyper--planes defined by the constraints. The simplex algorithm starts at an arbitrary exposed point of this polyeder and then in moves along one edge to another exposed point with a better objective value. This step is repeated until the exposed point with the minimal or maximal objective value is found.
\subsection{Boolean Satisfiability Problems}
\label{sec:MathBooleanSat}
In a classic boolean satisfiability problem (SAT) all variables are within the boolean domain and can take the values $true$ and $false$ or $0$ and $1$ respectively. The constraint relations are expressed by a boolean formula.  The task is to find an assignment to the variables that makes the formula true. A simple example of a boolean formula is given in equation (\ref{boolFormula}).
\begin{eqnarray}
x_1 \land \neg x_2  \lor \neg x_1 \land {x_2}
\label{boolFormula}
\end{eqnarray}
Any boolean formula can be normalised to a conjunction of disjunctive clauses, the so--called \emph{conjunctive normal form} (CNF). The boolean satisfiability problem is decidable, but belongs to the class of NP-complete problems. Thus algorithms solving this problem are intractable. However, there are specializations of the SAT problem for which a solution can be computed in polynomial time, for example 2-SAT where each disjunctive clause in the CNF consists of at most 2 \emph{literals}. A literal can either be a variable or the negation of a variable.\\
An important generalisation of the SAT problem is the \emph{satisfiability modulo theories} (SMT) problem. Here, instead of literals, sentences can appear that evaluate to true or false in some theory. Common background theories used for SMT are the free theory, linear arithmetic, or the theory of bit vectors. In the equations (\ref{eqn:SMTExample})-(\ref{eqn:SMTExampleEnd}) we see an example formula containing propositions in linear arithmetic, integer arithmetic, and one boolean literal.
\begin{eqnarray}
\label{eqn:SMTExample}
x_1,x_2\in \mathbb{R}, \quad x_3 \in \mathbb{Z},\quad x_4\in \mathbb{B}\\
\label{eqn:SMTExampleEnd}
(x_1\leq 5) \land (-x_2\leq 10) \lor (x_3=2) \land x_4
\end{eqnarray}
The decidability of SMT problem formulations depends on the background theories used. If the SMT is restricted to a set of decidable background theories then the SMT is decidable. If undecidable theories such as non linear arithmetic including transcendent functions are allowed then the SMT is undecidable. The well--known SMT solver CVC currently implements a large number of logical theories and their combinations \cite{cvc}\\
DPLL \cite{DPLL} is a classic algorithm solving SAT problems. The DPLL algorithm combines a backtracking search and local consistency checks. In the backtracking step one literal is selected and the problem splits up in two sub--problems, one in which the selected literal is assigned true and one, where it is set to false. All disjunctive clauses that become true by the assignment can be removed from the formula, and from those clauses that do not evaluate to true the assigned literal is removed. When there is a clause consisting of only one literal this literal can only be assigned in one way to make that clause true. In unit propagation this literal will be assigned and all clauses containing that literal can be removed from the formula. From all clauses containing the opposite literal the literal is removed. Unit propagation is repeated until there are no more clauses containing a single literal. Next pure literals are eliminated. A pure literal is a literal that is only present with one polarity. When a variable is for example only occurring as negative literal one can assign that variable to false and all clauses containing the negative literal are evaluating to true and can be removed. If in the end there is one empty clause, that is, a clause for which all literals are assigned and evaluated to false, then the current sub--problem is not satisfiable and one has to backtrack. If there are no more clauses left that means for the current assignment of literals every clause contains at least one literal evaluating to true then a satisfying assignment for the variables has been found.
%There are instances of SAT that are NP-complete and thus are in practice infeasible to solve although the corresponding decision problem is always decidable and DPLL is deterministic.\\
\subsection{Properties of the Search Space}
Every specialization of the CSP is imposing constraints on the formulation of constraints and on the selection of domains. For the problems presented so far, we focused on the ways constraints are stated. In this section we present further problems that can be obtained by strengthening or relaxing the constraints imposed on the selection of domains.
\subsubsection{Integer Programming}
When all variables in an CSP are in the discrete domain of natural numbers we call the CSP an \emph{integer program} (IP). Most integer programs are NP--complete. Well--known instances are the discrete logarithm problem and the factorisation of numbers with only two prime factors. A constraint satisfaction problem with variables in the domain of natural numbers as well in the domain of real numbers is called a \emph{mixed integer problem} (MIP). Optimisation problems, convex programs, and linear programs can be generalised by adding variables in the domain of natural numbers. While all convex optimisation problems with only continuous domains can be solved in polynomial time, the introduction of variables with discrete domains often makes the problem much more complex. A linear program with only discrete domains is called \emph{linear integer program} (LIP) and it is called a \emph{mixed linear integer program} (MILP) when it has both discrete and continuous domains. We call an IP or MIP whose \emph{continuous relaxation} is a convex problem a \emph{convex mixed integer program}. The continuous relaxation of a mixed integer program is the mathematical program where all discrete domains are replaced by corresponding continuous domains. For example, the set 
$\left\lbrace 1,2,3 \right\rbrace $
 could be replaced by the interval 
 $\left[ 1,3 \right] $
 .\\
An example of the convex mixed integer problem is as follows:
\begin{eqnarray}
x_1,x_2\in \mathbb{Z},\quad x_3\in \mathbb{R}\\
\text{minimise:}\quad x_3 \\
\text{subject to:}\quad x_1^2 + x_2^2 - 10.5 + x_3 \leq 0 \\
\text{subject to:}\quad x_3 \geq 0
\end{eqnarray}
One possible solution to this problem is $x_1=1$ and $x_2=3$ and the optimal value for $x_3$ is $0.5$. Without the integral constraint on $x_1$ and $x_2$ the solution to this problem could be computed by an interior point method in polynomial runtime; $x_3$ would then be $0$. With $x_1,x_2\in \mathbb{N}$ one can estimate an upper and a lower bound for $x_1$ and $x_2$ and then needs to try out all combinations of possible values for those two variables.\\
To solve a mixed integer problem a combination of different algorithms is used. One strategy is the \emph{cutting--planes} method. For cutting--planes first the optimal solution of the continuous relaxation is computed. If the optimal solution is integral in all the components that are required to be an integer we are done. If that is not the case a constraint is added such that all feasible points are still within the new feasible set, but the currently optimal solution of the continuous relaxation is excluded. Then, the solution of the continuous relaxation of the new problem is computed. This repeats until no more additional constraint can be found or the solution is integral in those components that are required to be integral. Mathematicians have found a variety of strategies to generate those additional constraints for the cutting--planes method. Another strategy is the branch--and--bound method. In branch--and--bound, the solution of the continuous relaxation is computed first and, in case the integrality constraints are not satisfied, the problem is split into sub--problems excluding the current solution of the continuous relaxation. For example the problem above might be split up into two sub--problems, by one time adding the constraint $x_2\geq 1$ and one time adding $x_2\leq 0$ to the original problem. This separation would exclude all solutions with $x_2$ between $0$ and $1$. The solution of the continuous relaxation, however, gives a lower bound for the optimal value. An upper bound for the optimal value of a sub--problem can be gained by a heuristic. If the lower bound of sub--problem A is above the upper bound for sub--problem B then sub--problem A can be pruned. Thus large portions of the search space are excluded from the search.
\subsubsection{Finite Search Spaces}
When each domain is a finite set then the search space is also finite. We call a constraint satisfaction problem with finite search space \emph{finite constraint satisfaction problem}. For a finite constraint satisfaction problem at least theoretically one can always find a solution or deny the existence of a solution after exhaustive search. In practice the search space is finite but often too large for exhaustive search.\\
%The class of mathematical programs contains instances whose decision problems are undecidable.
%In general CSPs with infinite domains and nonlinear algebraic constraints are undecidable. 
%There are some heuristic algorithms capable of solving many instances of those problems. There exist problem instances for which algorithms tend to run forever. 
%One option to break down problems with continuous or infinite search space is reducing its search space to a finite discrete set of possible values. This excludes the largest portion of the search space but makes the problem handleable with existing constraint programming systems. This technique is called \emph{bounded model checking}. The concept of bounded model checking matches pretty well with the fact that a computer can only encode finite sets. It is suitable to find a solution if there is one but if it does not find a solution it is not a guarantee that the original problem does not have a solution.\\
Finite constraint programs can be solved by reducing the domains of variables by constraint propagation, and local consistency checks, and backtracking when an inconsistency is found \cite{ConstraintPropagation}. Constraint propagation is a kind of logical inference and based on rules for reasoning. For example from the two constraints $x\leq 5$ and $y \leq x$ one can conclude that $y\leq 5$, thus the domain of y has been reduced. Examples of working constraint programming systems are B-Prolog and SWI-Prolog \cite{citation needed}. %A well known bounded model checker is SMV \cite{citation needed}. 
A different approach for solving finite constraint programs is stating the problem as an integer program and solving it with a combination of branch--and--bound and the cutting--planes algorithm.
\input{uml.tex}
\section{The AMPL Modelling System}
\label{sec:AMPL}
A Mathematical Programming Language (AMPL) from Bob Fourer \cite{AMPL} is an algebraic modelling language and also a software system interfacing different solvers capable of finding valid assignments for modelled variables. The AMPL system accepts three kinds of input: first there is a command language telling AMPL what to do and allowing the user to interact with the solver. Then AMPL has a modelling language in which different kinds of mathematical programs can be formalised. And last but not least AMPL offers a possibility to enter data for parameterised mathematical programs. In this section we will shortly explain the architecture of the AMPL software system and the concepts of each of those languages that are important for our thesis.
\subsection{Architecture of the AMPL System}
\subsection{Command Language}
When AMPL is started in interactive mode it shows a command prompt requiring the user to either enter commands or directly modify the AMPL Model. When AMPL is started with an AMPL script in the command line arguments it operates in batch mode.
The normal workflow using AMPL is loading an AMPL model from a file or directly entering the AMPL Model into the console. Then one switches into the data entering mode or and inputs specific values for every parameter of the loaded AMPL Model or directly loads the data from another file. Now the model is ready to be solved by one of the solvers interfacing with AMPL. Therefore we need to tell AMPL which solver shall be used and possibly set some further options. Then the solve command is issued and AMPL will return as soon as either a solution is found, an error has occurred or the AMPL model has been found to be infeasible with the entered parameters. When AMPL returns from the solve process reporting that a solution has been found one will use the show command in order to print the generated variable assignments.
Further AMPL provides commands to reset the currently loaded data or data and model. Also commands for making on the fly modifications of the AMPL model and data without a complete reset are available. For detailed reference of the commands the AMPL System supports we refer to the AMPL reference manual in the appendix of \cite{AMPL}.
\subsection{Modelling Language}
The AMPL modelling language is the means used to formalise parameterised constraint satisfaction problems and parameterised constrained optimisation problems. 
The modelling language supports several model entities. The supported model entities relevant for our thesis are sets, parameters, variables, constraints and objectives. Further we are using set expressions, index expressions and arithmetic or logical expressions. We will start by explaining the expression types and then introduce the afore mentioned model entities in the given order.
\subsubsection{Expressions}
\paragraph{Set and Index Expressions}
A set expression specifies a collection of values. The easiest way to specify a set is by explicitly naming each element e.g. \verb&1 2 3 4& specifies the set $\lbrace 1,2,3,4\rbrace$. A set containing a range of integers can also be specified more efficiently by stating \verb&1..4&. AMPL supports some set operations allowing to specify the union or intersection of two set expressions.\\
Another important expression using the set expressions are index expressions. An index expression consists of an index variable and a set expression specifying the set of values, which the index variable can take. Index expressions are used to iterate through a collection. An index expression in AMPL looks like \verb&{i in 0..4}& where i is the index variable which takes any integer value between 0 and 4.
\paragraph{Arithmetic, Logic, Relational Expressions}
In AMPL arithmetic and logical expressions can be composed of a variety of arithmetic functions, constant values, variables and parameters. AMPL has built in the basic arithmetic logical operations such as +,-,*,/,and,or,not and also the exponentiation and some further functions like sin, cos, if--then--else. The set of functions available in AMPL can even be extended by loading external function libraries. The syntax here is very intuitive. Examples for valid expressions evaluating to true or false are:
\verb&x<5; a=sin(b)&; \verb&(a=5) and (not (b<=sin(c)))&. Arithmetic expressions returning a numerical value are: \verb&x&; \verb&if (x<=5) then (10) else (11)&; \verb&cos(b)&; \verb&max(a,b,10)&. 
We assume the used literals x,a,b and c to be names of declared variables or parameters.
\subsubsection{Sets}
A set is a container holding a collection of values. It is declared with the keyword \verb=set= it has a name and potentially some attributes. A set can have several dimensions, be ordered or unordered and the default contents can be specified. The contents of the set can be required to be a subset of some set expression. A set expression is used to specify the elements contained in a set. The content of a set can be directly specified in the model or data section. When the content of a certain set is specified in the data then the model only contains a declaration of the set.\\
The simplest set declaration would be: set A; just declaring a one dimensional set named A whose contents have to be specified in the data section. 
A set declared as \verb&set A within 0..4 default 1 3& declares a set whose contents need to be a subset of $\lbrace 0,1,2,3,4\rbrace$ and by default, when nothing else is specified in the data the set will hold the elements 1 and 3.
% The syntax of a set declaration is 
% \begin{algorithm}
% \begin{description}
% \item[<set declaration> ::=] ``set'', <name>, <indexingExpression>, <attributes>?, ``;'' ;
% \end{description}
% \caption{EBNF of the used subset of the AMPL modelling language}
% \label{alg:OCLEBNF}
% \end{algorithm}
% The content of sets are specified via set expressions such as \verb=1..4= meaning all integers in the range from 1 to 4 or content of sets can also be specified by explicitly naming each entry or by means of set operations performed on other sets e.g. \verb&set a = b union c&. The content of a set can be included into the model, but they can also be specified in the data section, then the model would only contain a declaration of a set. The contents of the set can be required to be a subset of some set expression. For example if a set is declared as \verb&set A within 0..4;& then it would be illegal to assign the contents \verb&A= 1 5;& to the set, because $\lbrace 1, 5\rbrace$ is not a subset of $\lbrace 0,1,2,3,4\rbrace$. \\
% Any declaration in AMPL can be declared as an indexed collection of declarations. An indexing expression usually looks like \verb&{i in 0..4}& meaning that the index variable i takes all integer values from 0 to 4. Now it is also possible to declare a set \verb&set A = 1..4& and then use the indexing expression \verb&{i in A}&.
% If we now declare an indexed collection of sets such as \verb&set B {i in A} = 0..i ;& that essentially declares four sets namely B[0], B[1], B[3] and B[4] with the set B[0] containing only one element 0 and B[1] contains 0 and 1 and so on.
\subsubsection{Parameters}
A parameter holds a numerical value which can be accessed anywhere in the model and it is fixed and usually specified in the data section. A basic parameter declaration looks like this:\verb=param b;=. This specifies a parameter b, that can be used anywhere in the model. More sophisticated features of parameters will not be used for our thesis.
\subsubsection{Variables}
A variable in AMPL has an identifier and holds a numerical value. It can either be discrete or continuous and have an upper and a lower bound. A continuous variable is specified with the statement \verb=var x;=. Any model entity can be declared as an indexed collection. A variable being declared as an indexed collection of variables will look like this: \verb=var x{i in 0..4};=. This statement essentially declares 5 different variables namely x[0], \ldots , x[4]. Variables can just like parameters be referenced anywhere in the AMPL model. When a solver is called the solver will try to assign the values of the variables in such a way, that all constraints in the model evaluate to true and the objective is optimised.
\subsubsection{Constraints}
A constraint in AMPL has a name and an expression evaluating to either true or false. As already explained for variables also constraints can be declared as an indexed collection of constraints. When this is done the index variable can also be accessed inside the expression of the constraint. The declaration \verb&such that MyConstraint{i in 0..4}: x[i] <= i*b;& declares 5 constraints named myConstraint[0], \ldots, myConstraint[4]. We assume that b is the parameter and x the indexed collection of variables we have declared in the last two paragraphs. Now each of the 5 constraints refers to another index of x and imposes an upper bound on it, which also depends on the index. We could also have explicitly written out all 5 constraints.
\subsubsection{Objectives}
An objective can either be the maximisation or the minimisation of an objective function. The objective in AMPL has a name and an expression evaluating to a numerical value and specifies whether to minimise or maximise the given expression. The declaration \verb&minimize totalCost: a + b + c;& specifies that the totalCost has to be minimised and tells us that the totalCost composes from the values a, b and c which can be either variables or parameters. 
\subsection{Entering Data}
Although it is possible to specify the values of parameters as well as the elements contained in the declared sets directly in the model it is often desirable to enter them separately as data. Data can be entered in two ways either by reading them from a file or by switching into the data mode and entering it on the console. We assume that in the model the parameter b and the set A has been declared. Entering \verb&param b := 5;& and \verb&set A := 0 2 5;& in the data mode would set b to 5 and set the contents of A to $\lbrace 0,2,5\rbrace$.
\section{Taxonomy of Model Based Testing}
Test Model,
Unit Test,
verdict,
Test data,
SUT,
Harness/ stubs,
declarative specification

\section{Preliminary Work}
\label{sec:RelatedWork}
\begin{figure}
\includegraphics[width=0.6\textwidth]{./pics/taxonomyOfMBT.pdf}
\caption{Overview of the Taxonomy of Model-Based Testing by Mark Utting \cite{utting2006taxonomy}}
\label{fig:UttingTaxonomy}
\end{figure}
Model--Based Testing came up in the 1990s. A variety of different modelling paradigms and languages as well as test generation methods have been proposed since then. Model based testing has also been applied on different scopes i.e. unit test or system testing. Mark Utting offers in \cite{utting2006taxonomy} a possible classification of approaches to Model--Based Testing in seven orthogonal dimensions. In Figure \ref{fig:UttingTaxonomy} we see an overview of possible categorisations of Model--Based Testing approaches. Any proposal on Model-Based Testing roughly consists of three important steps: Specifying what the input model is, generating some abstract representation of test cases, refining the abstract test cases into concrete executable test cases by determining the necessary input data and potentially also providing an oracle value for the expected output. The rest of this section is structured according to those three steps and in each subsection we will shortly present the propositions made in different publications and use Mark Uttings taxonomy to classify them and to position our own thesis relative to them.
%in we will present  refer to several other publications and position our own thesis. The rest of this section is organized just 
% 
%  that means telling whether it models the behaviour of the SUT or whether it models its environment e.g. typical use cases. Usually a system is build according to a specification the specification can be formalized in a model from which can serve as a common source for implementation and test generation or there is a separate model for both purposes. and also the tests are derived from the specification.  with the help of the taxonomy proposed by M. Utting.
\subsection{Test Models}
In \cite{lackner2012modeling} Lackner and Schlingloff propose to build a test model formalising the requirements independent from the implementation and to generate test cases from it. They present three transition based modelling paradigms suitable for automated test case generation. They propose Abstract State Machines, UML2 StateMashines and Timed Automata. Also early research on Model--Based Testing performed by A. Abdurazik and Jeff Offutt \cite{Offutt:1999:GeneratingTestsFromUmlSpec} proposed using UML state charts as test model to generate system level test cases from them. The same authors proposed in \cite{Abdurazik00usingumlCollaborationTestGeneration} UML collaboration diagrams as test model. Stefan Wei{\ss}leder and Dehla Sokenou propose in \cite{weissleder2008automatic} using UML state models together with UML class models and OCL pre- and post--conditions as test models.\\
It is very common to use state machines as the test model less research is performed on generating unit tests from UML Activities. Wang Linzhang et al. propose in \cite{Linzhang04GeneratingTestCasefromActivityGrayBoxMethod} Using UML Activities. They propose to generate test cases from an Activity modelling an Operation in the design model. They also claim to have implemented a proof--of--concept tool called UMLTGF which unfortunately was unavailable for review. Another proposal using UML Activities as test model comes from Chen Minsong et al. \cite{mingsong2006automatic}. They propose using an activity diagram to automate the selection of a subset from a set of randomly generated unit tests for a set of Java classes and methods. In \cite{kundu2009novel} Debasish Kundu and Debasis Samanta consider UML Activities specifying use cases of the system under test. Further work on generating test cases from activity diagrams has been performed by \cite{Patel12TestCaseFormationUsigUMLActivityDiagram}\\
Achim D. Bruckner and Burkhard Wolff propose in \cite{brucker2012theoremProverBasedTesting} a fully theorem proofer and constraint solver based approach to test generation. Thus their input models are entered by means of a functional programming paradigm. They consider models of the system under test as well as additional information about how the system shall be tested as input.\\
For our own work we use as input some details from the UML Class model and an UML Activity modelling the inner workings of the system under test. System under test is in our case one operation. The model we use for test generation shares its control flow structure with the model used to generate the implementation similar to \cite{Linzhang04GeneratingTestCasefromActivityGrayBoxMethod}. The information needed to be able to derive test data is added separately to the test model, not shared with the development model, in the form of OCL pre- and post--conditions and guards. The use of OCL constraints is similar to the work of Stefan Wei{\ss}leder and Dehla Sokenou \cite{weissleder2008automatic}. We consider our input models deterministic, untimed and discrete.% Then they select among the randomly generated unit tests a set of unit tests whose execution traces correspond to a certain set of control flow paths from an activity diagram.
%\
% Our test models model one function of the SUT and we use a common model for development and test generation. thus the scope of our approach is unit testing  And 
\subsection{Test Generation}
In the test generation coverage criteria are a widely accepted means to measure the quality of a test suite and steer the test generation. Aynur Abdurazik and Jeff Offutt proposed in \cite{Offutt:1999:GeneratingTestsFromUmlSpec} a hand full of coverage criteria concerned with the structure of the test model. By structure we mean the nodes and the arcs of the state chart they used as input. They present path search algorithms to find transitions sequences fulfilling the proposed coverage criteria.
%Further 3 mor sophisticated covera
%Among others they proposed transition coverage, that means the set of generated test cases should at least trigger each transition in the test model once. They also presented full sequence coverage, which basically means that every possible transition sequence in a state chart shall be satisfied by one test case which is in general impossible, since a state chart with loops contains infinitely many 
Puneet E. Patel and Nitin N. Patil compare in \cite{Patel12TestCaseFormationUsigUMLActivityDiagram} two different path finding algorithm selecting control flow paths within an activity diagram as abstract test cases. Also \cite{kundu2009novel} and \cite{Linzhang04GeneratingTestCasefromActivityGrayBoxMethod} propose mainly some kind of graph search as technology to find suitable test cases.\\
%finding a paths to select test cases in a way that they fulfil some coverage of arcs or arc sequences and nodes in an activity diagram. This is also a structural coverage criterion. 
%The coverage criterion of 
Stefan Wei{\ss}leder and Dehla Sokenou presented in \cite{weissleder2008automatic} is data oriented approach to select test cases. They propose to use abstract interpretation to derive partitions of the domain of input values. They then propose to select values at the boundaries of the computed partitions as test data.
In Stefan Wei{\ss}leders Ph.D Thesis \cite{ParTeG} we found the most detailed and complete collection of different model structure and data oriented coverage criteria. The source code of ParTeG, the proof--of--concept tool associated with this thesis, is freely available at \cite{sf.parteg} and we were able to test it. It uses graph search in combination with abstract interpretation and a comprehensive framework allowing the user to steer which coverage criteria the generated test cases will adhere to.\\
A comprehensive approach to automated test generation based on automated theorem proofing and constraint solving is presented by Achim D. Brucker and Burkhart Wolff in \cite{brucker2012theoremProverBasedTesting}. They generate test cases by applying natural deduction to a %a theorem prover rewriting rules to a 
test case specification given in the input language of a theorem prover. The so called test theorem resulting from the natural deduction is a sequence of executable statements which serves as abstract test case. With a constraint solver concrete test data is computed for each abstract test case.\\
In our thesis we use an easy to implement path search algorithm to generate abstract test cases. The path search is supported by abstract interpretation and constraint 
%Among other all those publications presented the model structure oriented full sequence/path coverage, which basically means that every possible arc sequence in a graph shall be satisfied by one test case. We use a slight relaxation of this coverage criterion for our thesis. Further more we will also hint how we can satisfy data oriented coverage criteria.\\
% 
\subsection{Test Data Generation}
Chen Minsong et al. \cite{mingsong2006automatic} combine random test case and data generation with graph structure oriented coverage criteria. Their approach is to randomly generate unit tests for a Java implementation and matching the execution traces of the randomly generated unit tests with the control flow paths found in an activity diagram. They then select a subset from the randomly generated test cases which covers all simple paths in the test model. A simple path is basically a control flow path executing each activity at most once. This is obviously a randomised approach to test data generation combined with a structural model coverage criterion.
Jan Peleska et al. \cite{peleska2011automated} describe a combination of abstract interpretation with constraint solving using an SMT solver in order to generate test data. They consider the execution of a test model as consecutive execution of a state transition function, which changes the state of the system. They have the concatenated state transition function and some further predicates solved by an SMT solver and support the solver by providing it with bounds for some variables deduced via abstract interpretation. 
Using OCL as input and trying to obtain test data by solving OCL constraints there have been several proposals on how exactly to find models making an OCL formula true. Shaukat Ali et al. proposed in \cite{ali2011search} using evolutionary or genetic algorithms to search for potential solutions of OCL constraints. Matthias P. Krieger and Alexander Knapp proposed in \cite{krieger2008executingUnderspecifiedOCL} using a SAT solver to find instantiations of variables fulfilling OCL constraints. They suppose to transform OCL formulas into boolean formulas with bounded quantifiers and uninterpreted functions. Consequently they use a model finder, based on a SAT solver, capable of handling those formulas to find assignments to the variables.\\
In \cite{malburg2011combining} Jan Malburg and Gordon Fraser propose a hybrid approach. On the top level they use a genetic algorithm evolving a population of candidate test data internally they provide guidance to the genetic algorithm by providing a special mutation operator performing dynamic symbolic execution. Also Microsofts tool PEX \cite{pex} is based on dynamic symbolic execution. Both publications propose to execute the implementation with random input values and generate new input values by collecting all path conditions along the executed control flow. Then they negate one of the path conditions and use a constraint solver to find a solution for the new constraint system. The generated solution is possible input data which is guaranteed to take another control flow path in the program.\\
Our own test data generation approach is based on symbolic execution of control flow paths in an activity diagram. We collect all the constraints along a control flow path and represent them in a constraint satisfaction problem. The result of symbolic execution is a set of constraints that can be solved by a constraint solver or search based method.
%Alloy \cite{jackson2002alloy} and Dresden OCL or Eclipse OCL are other projects that aim at executing or at least evaluating OCL specifications over a given model.
% performs 
%Many papers suppose the use of state of the art SMT solvers such as HOL or CVC to solve OCL post--conditions, pre--conditions and of operations and invariants embedded to get possible input values for functions that can be used as 
%But solving OCL constraints as a CSP is only one part of generating test data from a UML Behaviour.
%Technology Model Checking. \cite{Xu09ModelCheckingUMLActivityDiagramsFDR}. 
% \subsection{Further Readings}
% Can intuition become rigorous \cite{Aleman00CanIntuitionBecomeRigorous?}
% RoclET \cite{jeanneret2006roclet}
% OCL Modularisation \cite{akehurst2007ocl}
% 
% \subsection{Existing Tools for Automated Test Generation}
% The only tool directly targeted at generating Unit Tests form A UML specification with OCL constraints that was freely available was ParTeG by Stephan Wei{\ss}leder. In his PhD thesis Stephan Wei{\ss}leder describes a framework for applying different control flow based as well as partition based coverage criteria to state machines. He also develops a theory how all those coverage criteria are interconnected and can be simulated by each other and a transformed version of the original Test Model\cite{ParTeG}.
% 
% Spex
% 
% tell about other test generating tools (commercial, published in Papers) and ParTeG as the only one where the source code is available.\cite{ParTeG}

